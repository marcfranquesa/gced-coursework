{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bB6LN1u3xOn"
   },
   "source": [
    "# Simple example script to illustrate fit/predict ML pipeline of scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T10:46:36.102809Z",
     "start_time": "2020-07-24T10:46:36.072899Z"
    },
    "id": "ZT-6k9BK3xOp"
   },
   "outputs": [],
   "source": [
    "# Uncomment to upgrade packages\n",
    "#!pip3 install pandas --upgrade --user --quiet\n",
    "#!pip3 install numpy --upgrade --user --quiet\n",
    "#!pip3 install scikit-learn --upgrade --user --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T10:46:37.283749Z",
     "start_time": "2020-07-24T10:46:36.952293Z"
    },
    "id": "LdkmvYfG3xOx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load `murders.txt` data from class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZxilZq_CNJ-X"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"murders.txt\", sep=\" \")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(df, alpha=0.8, figsize=(7, 7), diagonal=\"kde\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put data into X matrix and y column\n",
    "\n",
    "X = df[[\"inhabitants\", \"poverty\", \"unemployment\"]].to_numpy()\n",
    "y = df[[\"murders\"]].to_numpy()\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train/test split for later validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=0\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train linear model to predict `murders` \n",
    "\n",
    "The `LinearRegression` model from scikit-learn uses the _least squares_ method explained in class to find linear coefficients $\\theta_0, \\theta_1, ..$, remember:\n",
    "\n",
    "$$\\theta_{lsm} = (X^T X)^{-1} X^T y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instantiate model's object\n",
    "model1 = LinearRegression()\n",
    "\n",
    "# train model's object with X,y data  (basically this is doing what the formula above shows)\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# coefficients (the _thetas_ are stored in these locations of the model; intercept is separate from rest)\n",
    "print(model1.coef_, model1.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show predictions + errors on training data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract learned coefficients\n",
    "theta_vector = np.array(model1.coef_[0]).reshape((3, 1))\n",
    "bias = model1.intercept_[0]\n",
    "\n",
    "# make predictions for training points\n",
    "y_pred = model1.predict(\n",
    "    X_train\n",
    ")  # basically doing: y_pred = X_train @ theta_vector + bias\n",
    "y_pred_sanity_check = (\n",
    "    X_train @ theta_vector + bias\n",
    ")  # sanity check, make sure they're the same in table below\n",
    "\n",
    "# compute squared error for each example\n",
    "abs_error = np.abs(y_pred - y_train)\n",
    "sq_error = np.square(y_pred - y_train)\n",
    "\n",
    "# print training data with predictions\n",
    "dict_data = {\n",
    "    \"poverty\": X_train[:, 1].ravel(),\n",
    "    \"target\": y_train.ravel(),\n",
    "    \"pred(sklearn)\": y_pred.ravel(),\n",
    "    \"pred(formula)\": y_pred_sanity_check.ravel(),\n",
    "    \"abs_error\": abs_error.ravel(),\n",
    "    \"squared_error\": sq_error.ravel(),\n",
    "}\n",
    "print(pd.DataFrame.from_dict(dict_data))\n",
    "\n",
    "# show _mean squared error_\n",
    "print(f\"\\nThe training mean squared error is: {mean_squared_error(y_pred, y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test trained linear model to predict `murders` on __unseen data__  (test partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on unseen test points (from test partition)\n",
    "y_pred = model1.predict(\n",
    "    X_test\n",
    ")  # basically doing: y_pred = X_test @ theta_vector + bias\n",
    "\n",
    "# compute squared error for each example\n",
    "abs_error = np.abs(y_pred - y_test)\n",
    "sq_error = np.square(y_pred - y_test)\n",
    "\n",
    "# show them in table\n",
    "dict_data = {\n",
    "    \"poverty\": X_test[:, 1].ravel(),\n",
    "    \"target\": y_test.ravel(),\n",
    "    \"pred\": y_pred.ravel(),\n",
    "    \"abs_error\": abs_error.ravel(),\n",
    "    \"squared_error\": sq_error.ravel(),\n",
    "}\n",
    "print(pd.DataFrame.from_dict(dict_data))\n",
    "\n",
    "print(f\"\\nThe TEST mean squared error is: {mean_squared_error(y_pred, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. `vander` polinomial expansion for next script..\n",
    "\n",
    "In the next script we are going to see how to expand the input dataset using polynomial features from original data.\n",
    "Here we show in a simple manner how to do this with [numpy's vander](https://numpy.org/doc/stable/reference/generated/numpy.vander.html) function,\n",
    "which just computes $[x^0, x^1, x^2, ..]$ from feature $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 5])\n",
    "deg = 3\n",
    "np.vander(x, deg + 1, increasing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "36bc7f9a9055f480cb73d8ea486ac439fe390d5591cca9e08d0b9b0f17fdecc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
