{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "g8SkT_9EiyqR",
   "metadata": {
    "id": "g8SkT_9EiyqR"
   },
   "source": [
    "# AA1 lab 05 - Resampling methods\n",
    "\n",
    "## Methods for evaluating and/or comparing/selecting models/hyperparameters\n",
    "\n",
    "\n",
    "Properly assessing the quality of **future** predictions of a trained model (i.e. its **predictive error**, or **generalization error**) is undoubtedly critical in order to be able to produce such a model. If we had access to more data, then all we would need to do is obtain them and assess the trained models with these new data examples. However, the typical scenario is to work with a finite sample and it is very costly or directly impossible to obtain new data. In this second scenario, we resort to **resampling methods** to make the most of our training data in order to:\n",
    "1. assess predictive performance, and \n",
    "2. select hyper-parameters and select most-promising models.\n",
    "\n",
    "This script includes examples of most common resampling mathods, from more simple to more sophisticated. Resampling methods are methods that partition the available data in various ways, in order to estimate **predictive error** on the basis of **validation** metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AUHLnMbqiyqV",
   "metadata": {
    "id": "AUHLnMbqiyqV"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z5Vusf5wiyqW",
   "metadata": {
    "id": "Z5Vusf5wiyqW"
   },
   "source": [
    "## Example 1: estimating predictive error with least-squares linear regression (no hyper-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F5vJszsEiyqW",
   "metadata": {
    "executionInfo": {
     "elapsed": 1916,
     "status": "ok",
     "timestamp": 1679073417167,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "F5vJszsEiyqW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    KFold,\n",
    "    cross_val_score,\n",
    "    RepeatedKFold,\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from numpy.random import uniform, normal\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set()\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.rcParams[\"image.cmap\"] = \"bwr\"\n",
    "plt.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "style.use(\"ggplot\") or plt.style.use(\"ggplot\")\n",
    "\n",
    "np.random.seed(123)  # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mSmtA3HkiyqX",
   "metadata": {
    "id": "mSmtA3HkiyqX"
   },
   "source": [
    "We use a simple linear data generating mechanism with Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b-4mo_-IiyqY",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1679073417167,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "b-4mo_-IiyqY"
   },
   "outputs": [],
   "source": [
    "def feval(x):\n",
    "    return -0.3 + 1.2 * x\n",
    "\n",
    "\n",
    "def fgen(N, sigma):\n",
    "    a = 0  # left x limit\n",
    "    b = 1  # right x limit\n",
    "\n",
    "    x = np.sort(uniform(a, b, N))\n",
    "    t = feval(x) + normal(loc=0, scale=sigma, size=N)\n",
    "    return x, t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "znF6clLniyqY",
   "metadata": {
    "id": "znF6clLniyqY"
   },
   "source": [
    "We start generating a sample of 10 examples generating the data assuming that has gaussian noise $N(0,1)$; this is going to be our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pqym0Z_XiyqY",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1679073417168,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "pqym0Z_XiyqY"
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "sigma = 1\n",
    "\n",
    "x, t = fgen(N, sigma)\n",
    "training_set = pd.DataFrame({\"input\": x, \"target\": t})\n",
    "\n",
    "X = training_set.input.to_numpy().reshape(-1, 1)\n",
    "y = training_set.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tO3dju0eiyqZ",
   "metadata": {
    "id": "tO3dju0eiyqZ"
   },
   "source": [
    "We visualize the generated data: red dots are the training datas, green line is true underlying data-generating line, blue line is least squares fitted line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9Rn1FmKWiyqZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1679073417560,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "9Rn1FmKWiyqZ",
    "outputId": "84d05e8e-cedd-43ca-a828-942df40ab754"
   },
   "outputs": [],
   "source": [
    "ols = LinearRegression()\n",
    "ols.fit(X, y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(training_set.input, training_set.target, \"o\")\n",
    "ax.plot(np.linspace(0, 1, num=2), feval(np.linspace(0, 1, num=2)), \"g-\")\n",
    "ax.plot(np.linspace(0, 1, num=2), [ols.intercept_, ols.intercept_ + ols.coef_[0]], \"b-\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dIyCfUtniyqa",
   "metadata": {
    "id": "dIyCfUtniyqa"
   },
   "source": [
    "Now we generate a test set using the same mechanism. The test set will be **very** large because we want to be able to assess the **generalization error** of our trained linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SCYvHqs0iyqb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "executionInfo": {
     "elapsed": 1301,
     "status": "ok",
     "timestamp": 1679073418857,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "SCYvHqs0iyqb",
    "outputId": "035962a5-e2d5-4be2-f344-bdbd586a91a5"
   },
   "outputs": [],
   "source": [
    "N_test = 1000\n",
    "x, t = fgen(N_test, sigma)\n",
    "test_set = pd.DataFrame({\"input\": x, \"target\": t})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(test_set.input, test_set.target, \"o\")\n",
    "ax.plot(training_set.input, training_set.target, \"bo\")\n",
    "ax.plot(np.linspace(0, 1, num=2), feval(np.linspace(0, 1, num=2)), \"g-\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qslUJzmjiyqb",
   "metadata": {
    "id": "qslUJzmjiyqb"
   },
   "source": [
    "Now we assess predictive error (we'll use MSE) using: \n",
    "1. training error \n",
    "2. train/val single split\n",
    "3. Monte-Carlo cross-validation (10x) \n",
    "4. k-fold cross-validation\n",
    "5. 10xk iterated cross-validation\n",
    "6. loocv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hUSMDFfciyqb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7564,
     "status": "ok",
     "timestamp": 1679073426418,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "hUSMDFfciyqb",
    "outputId": "2f0bc3f4-3ea8-4800-9396-72ab3b2fcdb8"
   },
   "outputs": [],
   "source": [
    "# 1. Training error\n",
    "ols = LinearRegression()\n",
    "ols.fit(X, y)\n",
    "training_error = mean_squared_error(y, ols.predict(X))\n",
    "\n",
    "# 2. Single Train/Validation error\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33)\n",
    "ols.fit(X_train, y_train)\n",
    "single_val_error = mean_squared_error(y_val, ols.predict(X_val))\n",
    "\n",
    "# 3. Monte carlo cross-val (with k=1 up to 'repeats' repetitions)\n",
    "repeats = 10\n",
    "scores = []\n",
    "for i in range(repeats):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33)\n",
    "    ols.fit(X_train, y_train)\n",
    "    scores.append(mean_squared_error(y_val, ols.predict(X_val)))\n",
    "mc_cross_val = np.cumsum(scores) / np.arange(1, len(scores) + 1)\n",
    "\n",
    "# 4. k-fold cross-validation\n",
    "all_k = range(2, N + 1)\n",
    "cross_val = np.zeros(N + 1)\n",
    "for k in all_k:\n",
    "    scores = -cross_val_score(ols, X, y, cv=k, scoring=\"neg_mean_squared_error\")\n",
    "    cross_val[k] = scores.mean()\n",
    "\n",
    "# 5. 10xk cross-val\n",
    "repeated_cross_val = np.zeros(N + 1)\n",
    "for k in all_k:\n",
    "    rkf = RepeatedKFold(n_splits=k, n_repeats=repeats)\n",
    "    this_k = []\n",
    "    for train_index, val_index in rkf.split(X):\n",
    "\n",
    "        x_train_fold = X[train_index]\n",
    "        y_train_fold = y[train_index]\n",
    "        x_val_fold = X[val_index, :]\n",
    "        y_val_fold = y[val_index]\n",
    "\n",
    "        ols.fit(x_train_fold, y_train_fold)\n",
    "        this_k.append(mean_squared_error(y_val_fold, ols.predict(x_val_fold)))\n",
    "\n",
    "    repeated_cross_val[k] = np.mean(this_k)\n",
    "\n",
    "# 6. LOOCV\n",
    "loocv_error = cross_val[N]\n",
    "\n",
    "# 7. True error (on large test set)\n",
    "X_test = test_set.input.to_numpy().reshape(-1, 1)\n",
    "y_test = test_set.target\n",
    "\n",
    "ols.fit(X, y)\n",
    "test_error = mean_squared_error(y_test, ols.predict(X_test))\n",
    "\n",
    "# print it\n",
    "print(f\"training: {training_error:.2f}\")\n",
    "print(f\"single train/val: {single_val_error:.2f}\")\n",
    "print(f\"MC train/val: {mc_cross_val}; average of all runs is {mc_cross_val.mean()}\")\n",
    "print(f\"k-fold cross-val: {cross_val[2:]}\")\n",
    "print(f\"10xk cross-val: {repeated_cross_val[2:]}\")\n",
    "print(f\"loocv: {loocv_error:.2f}\")\n",
    "print(f\"test: {test_error:.2f}\")\n",
    "print(f\"irreducible error (sigma^2): {sigma**2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ng2p9xB-iyqc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 1750,
     "status": "ok",
     "timestamp": 1679073428165,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "Ng2p9xB-iyqc",
    "outputId": "2394b4f5-9599-48e9-e6f8-5bfd6447af03"
   },
   "outputs": [],
   "source": [
    "# put it all in a dataframe for easy plotting\n",
    "from matplotlib import cm\n",
    "\n",
    "data = [None] * len(all_k)\n",
    "for i, k in enumerate(all_k):\n",
    "    data[i] = [\n",
    "        k,\n",
    "        training_error,\n",
    "        single_val_error,\n",
    "        mc_cross_val[k - 1],\n",
    "        cross_val[k],\n",
    "        repeated_cross_val[k],\n",
    "        loocv_error,\n",
    "        test_error,\n",
    "        sigma**2,\n",
    "    ]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data,\n",
    "    columns=[\n",
    "        \"k\",\n",
    "        \"training\",\n",
    "        \"single train/val\",\n",
    "        \"Monte-Carlo cross-val (k times)\",\n",
    "        \"k-fold cross-val\",\n",
    "        \"10xk cross-val\",\n",
    "        \"loocv\",\n",
    "        \"true\",\n",
    "        \"irreducible\",\n",
    "    ],\n",
    ")\n",
    "df.plot(x=\"k\", figsize=(14, 6), xticks=all_k, colormap=cm.get_cmap(\"Set1\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yc9tMMdtiyqc",
   "metadata": {
    "id": "yc9tMMdtiyqc"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mZ8M7oMyiyqc",
   "metadata": {
    "id": "mZ8M7oMyiyqc"
   },
   "source": [
    "## Example 2: model selection with single train/val split between ols and ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FETtWsJCiyqd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "executionInfo": {
     "elapsed": 989,
     "status": "ok",
     "timestamp": 1679073429151,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "FETtWsJCiyqd",
    "outputId": "7162de72-df8d-4ab9-ea65-1b0dc2cd6563"
   },
   "outputs": [],
   "source": [
    "# first generate dataset (we use same mechanism as above)\n",
    "N = 30\n",
    "sigma = 1\n",
    "\n",
    "X, y = fgen(N, sigma)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(X, y, \"o\")\n",
    "ax.plot(np.linspace(0, 1, num=2), feval(np.linspace(0, 1, num=2)), \"g-\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OXIR_Ez5iyqd",
   "metadata": {
    "id": "OXIR_Ez5iyqd"
   },
   "source": [
    "### (1) split available data into training + test set\n",
    "\n",
    "notice that we call `X_learn` the training partition to avoid clash with train later on on train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P1i0DHZCiyqd",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1679073429151,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "P1i0DHZCiyqd"
   },
   "outputs": [],
   "source": [
    "X_learn, X_test, y_learn, y_test = train_test_split(X.reshape(-1, 1), y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4iy18DNBiyqd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1679073429152,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "4iy18DNBiyqd",
    "outputId": "aabc5265-e98d-4011-ff47-77fb0e0caceb"
   },
   "outputs": [],
   "source": [
    "X_learn.size, y_learn.size, X_test.size, y_test.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9x83ezjviyqe",
   "metadata": {
    "id": "9x83ezjviyqe"
   },
   "source": [
    "### (2) use train/val split as resampling method for tuning $\\lambda$ and selecting model\n",
    "\n",
    "Notice that in this step **we do not look into the test set at all**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZaNf_BECiyqe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1679073429559,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "ZaNf_BECiyqe",
    "outputId": "bd8c5845-e366-410c-f61c-29debacfd21e"
   },
   "outputs": [],
   "source": [
    "# split \"learn\" into train + validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_learn, y_learn, test_size=0.5)\n",
    "\n",
    "# train ols model and estimate performance on validation set\n",
    "ols = LinearRegression()\n",
    "ols.fit(X_train, y_train)\n",
    "ols_val_score = mean_squared_error(y_val, ols.predict(X_val))\n",
    "\n",
    "# train ridge model with different lambdas and estimate performance on validation set\n",
    "all_lambdas = [1e-10, 1e-5, 1e-4, 1e-3, 1e-2, 0.1, 0.5, 1, 5, 10, 50, 100]\n",
    "ridge_val_score = np.zeros(len(all_lambdas))\n",
    "for i, l in enumerate(all_lambdas):\n",
    "    lr = Ridge(alpha=l)\n",
    "    lr.fit(X_train, y_train)\n",
    "    ridge_val_score[i] = mean_squared_error(y_val, lr.predict(X_val))\n",
    "\n",
    "# show validation scores\n",
    "print(f\"OLS validation score: {ols_val_score}\")\n",
    "print(f\"Ridge validation scores:\")\n",
    "for i, l in enumerate(all_lambdas):\n",
    "    print(f\"\\t lambda={l}; validation_score: {ridge_val_score[i]:.2f}\")\n",
    "print()\n",
    "\n",
    "# select winner..\n",
    "best = np.argmin(ridge_val_score)\n",
    "best_lambda = all_lambdas[best]\n",
    "print(f\"Best lambda in ridge is {best_lambda} with score {ridge_val_score[best]:.2f}\")\n",
    "print(f\"OLS has score {ols_val_score:.2f}\")\n",
    "if ridge_val_score[best] < ols_val_score:\n",
    "    print(f\"So, Ridge with lambda {best_lambda} wins.\")\n",
    "    winner = Ridge(alpha=best_lambda)\n",
    "else:\n",
    "    print(f\"So, OLS wins.\")\n",
    "    winner = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AnFBzXV0iyqe",
   "metadata": {
    "id": "AnFBzXV0iyqe"
   },
   "source": [
    "### (3) build winning model on whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0J50cd58iyqe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1679073429560,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "0J50cd58iyqe",
    "outputId": "1de3e598-0a1b-4a97-f398-87ef84165953"
   },
   "outputs": [],
   "source": [
    "winner.fit(X_learn, y_learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EudkvGOWiyqf",
   "metadata": {
    "id": "EudkvGOWiyqf"
   },
   "source": [
    "### (4) estimate predictive error of trained final model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cnOFAnnLiyqf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1679073429560,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "cnOFAnnLiyqf",
    "outputId": "c4316e88-e462-4872-d859-374a737d313b"
   },
   "outputs": [],
   "source": [
    "y_pred = winner.predict(X_test)\n",
    "test_score = mean_squared_error(y_test, y_pred)\n",
    "print(f\"The TEST mse of final model is: {test_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JS7W8KMuiyqf",
   "metadata": {
    "id": "JS7W8KMuiyqf"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DLf57_uoiyqf",
   "metadata": {
    "id": "DLf57_uoiyqf"
   },
   "source": [
    "## Example 3: model selection with 3-fold cross-validation between ols and ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GapX38VTiyqf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "executionInfo": {
     "elapsed": 728,
     "status": "ok",
     "timestamp": 1679073430284,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "GapX38VTiyqf",
    "outputId": "c74b5c1c-d09a-4e6c-d2b6-50a4d99a9c02"
   },
   "outputs": [],
   "source": [
    "# first generate dataset (we use same mechanism as above)\n",
    "N = 30\n",
    "sigma = 1\n",
    "\n",
    "X, y = fgen(N, sigma)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(X, y, \"o\")\n",
    "ax.plot(np.linspace(0, 1, num=2), feval(np.linspace(0, 1, num=2)), \"g-\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EHO1Jepziyqg",
   "metadata": {
    "id": "EHO1Jepziyqg"
   },
   "source": [
    "### (1) split available data into training + test set\n",
    "\n",
    "notice that we call `X_learn` the training partition to avoid clash with train later on on train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sBbZnXk5iyqg",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1679073430285,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "sBbZnXk5iyqg"
   },
   "outputs": [],
   "source": [
    "X_learn, X_test, y_learn, y_test = train_test_split(X.reshape(-1, 1), y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ReYbxaqNiyqg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1679073430285,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "ReYbxaqNiyqg",
    "outputId": "3c3c06c1-f934-4447-8222-cb39b628891e"
   },
   "outputs": [],
   "source": [
    "X_learn.size, y_learn.size, X_test.size, y_test.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TzHuXQHviyqg",
   "metadata": {
    "id": "TzHuXQHviyqg"
   },
   "source": [
    "### (2) use 3-fold cross-val as resampling method for tuning $\\lambda$ and selecting model\n",
    "\n",
    "Notice that in this step **we do not look into the test set at all**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O2boiO7giyqg",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1679073430286,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "O2boiO7giyqg"
   },
   "outputs": [],
   "source": [
    "# do cross-val by hand because OLS does not have 'CV' option..\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# these accumulate scores for each fold, at the end we average\n",
    "ols_val_score = []\n",
    "ridge_val_score = [[] for _ in all_lambdas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UrPxXD0miyqg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1679073430286,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "UrPxXD0miyqg",
    "outputId": "fe420187-53ca-4d2d-f3f0-7b100bc2c79a"
   },
   "outputs": [],
   "source": [
    "for train_index, val_index in kf.split(X_learn):\n",
    "    X_train = X_learn[train_index]\n",
    "    X_val = X_learn[val_index]\n",
    "    y_train = y_learn[train_index]\n",
    "    y_val = y_learn[val_index]\n",
    "\n",
    "    # train ols model and estimate performance on validation set\n",
    "    ols = LinearRegression()\n",
    "    ols.fit(X_train, y_train)\n",
    "    ols_val_score.append(mean_squared_error(y_val, ols.predict(X_val)))\n",
    "\n",
    "    # train ridge model with different lambdas and estimate performance on validation set\n",
    "    all_lambdas = [1e-10, 1e-5, 1e-4, 1e-3, 1e-2, 0.1, 0.5, 1, 5, 10, 50, 100]\n",
    "    for i, l in enumerate(all_lambdas):\n",
    "        lr = Ridge(alpha=l)\n",
    "        lr.fit(X_train, y_train)\n",
    "        ridge_val_score[i].append(mean_squared_error(y_val, lr.predict(X_val)))\n",
    "\n",
    "# average accross all folds..\n",
    "ols_val_score = np.mean(ols_val_score)\n",
    "ridge_val_score = [np.mean(x) for x in ridge_val_score]\n",
    "\n",
    "# select winner..\n",
    "best = np.argmin(ridge_val_score)\n",
    "best_lambda = all_lambdas[best]\n",
    "print(f\"Best lambda in ridge is {best_lambda} with score {ridge_val_score[best]:.2f}\")\n",
    "print(f\"OLS has score {ols_val_score:.2f}\")\n",
    "if ridge_val_score[best] < ols_val_score:\n",
    "    print(f\"So, Ridge with lambda {best_lambda} wins.\")\n",
    "    winner = Ridge(alpha=best_lambda)\n",
    "else:\n",
    "    print(f\"So, OLS wins.\")\n",
    "    winner = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fmnH-usDiyqh",
   "metadata": {
    "id": "fmnH-usDiyqh"
   },
   "source": [
    "### (3) build winning model on whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pPV0971giyqh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1679073430499,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "pPV0971giyqh",
    "outputId": "2235f080-1331-45d6-cc0d-7542973b106d"
   },
   "outputs": [],
   "source": [
    "winner.fit(X_learn, y_learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9H4tPWhFiyqh",
   "metadata": {
    "id": "9H4tPWhFiyqh"
   },
   "source": [
    "### (4) estimate predictive error of trained final model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Wsh8rPEXiyqh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1679073430499,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "Wsh8rPEXiyqh",
    "outputId": "1edffe8d-f401-44cf-9083-37932ebbd8fd"
   },
   "outputs": [],
   "source": [
    "y_pred = winner.predict(X_test)\n",
    "test_score = mean_squared_error(y_test, y_pred)\n",
    "print(f\"The TEST mse of final model is: {test_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LT6kO1V0iyqh",
   "metadata": {
    "id": "LT6kO1V0iyqh"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "av2QMuVJiyqi",
   "metadata": {
    "id": "av2QMuVJiyqi"
   },
   "source": [
    "## Example 4: model selection with LOOCV between ols and ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfVQrVyGiyqi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "executionInfo": {
     "elapsed": 1004,
     "status": "ok",
     "timestamp": 1679073431501,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "dfVQrVyGiyqi",
    "outputId": "58659d45-5135-458c-8826-72bac6684378"
   },
   "outputs": [],
   "source": [
    "# first generate dataset (we use same mechanism as above)\n",
    "N = 30\n",
    "sigma = 1\n",
    "\n",
    "X, y = fgen(N, sigma)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(X, y, \"o\")\n",
    "ax.plot(np.linspace(0, 1, num=2), feval(np.linspace(0, 1, num=2)), \"g-\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W2y_XBNLiyqi",
   "metadata": {
    "id": "W2y_XBNLiyqi"
   },
   "source": [
    "### (1) split available data into training + test set\n",
    "\n",
    "notice that we call `X_learn` the training partition to avoid clash with train later on on train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AIYIVMe1iyqi",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1679073431502,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "AIYIVMe1iyqi"
   },
   "outputs": [],
   "source": [
    "X_learn, X_test, y_learn, y_test = train_test_split(X.reshape(-1, 1), y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RqXLgNDaiyqi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1679073431502,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "RqXLgNDaiyqi",
    "outputId": "0bbcd111-aa0b-461d-88e8-1e4119d731f8"
   },
   "outputs": [],
   "source": [
    "X_learn.size, y_learn.size, X_test.size, y_test.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xsyGcTB_iyqi",
   "metadata": {
    "id": "xsyGcTB_iyqi"
   },
   "source": [
    "### (2) use LOOCV as resampling method for tuning $\\lambda$ and selecting model\n",
    "\n",
    "Notice that in this step **we do not look into the test set at all**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jgS1d5F7iyqj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1388,
     "status": "ok",
     "timestamp": 1679073432886,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "jgS1d5F7iyqj",
    "outputId": "172e642b-913c-44aa-eb9b-2f9e70b7ccbd"
   },
   "outputs": [],
   "source": [
    "# we use the power of scikit-learn to make our lives easier using `cross_val_score` which does the cross-val for us\n",
    "\n",
    "all_lambdas = [1e-10, 1e-5, 1e-4, 1e-3, 1e-2, 0.1, 0.5, 1, 5, 10, 50, 100]\n",
    "\n",
    "lr = LinearRegression()\n",
    "ols_loocv = np.mean(\n",
    "    -cross_val_score(\n",
    "        lr, X_learn, y_learn, cv=len(y_learn), scoring=\"neg_mean_squared_error\"\n",
    "    )\n",
    ")\n",
    "\n",
    "ridge_loocv = np.zeros(len(all_lambdas))\n",
    "for i, l in enumerate(all_lambdas):\n",
    "    r = Ridge(alpha=l)\n",
    "    ridge_loocv[i] = np.mean(\n",
    "        -cross_val_score(\n",
    "            r, X_learn, y_learn, cv=len(y_learn), scoring=\"neg_mean_squared_error\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# select winner..\n",
    "best = np.argmin(ridge_loocv)\n",
    "best_lambda = all_lambdas[best]\n",
    "print(f\"Best lambda in ridge is {best_lambda} with score {ridge_loocv[best]:.2f}\")\n",
    "print(f\"OLS has score {ols_loocv:.2f}\")\n",
    "if ridge_loocv[best] < ols_loocv:\n",
    "    print(f\"So, Ridge with lambda {best_lambda} wins.\")\n",
    "    winner = Ridge(alpha=best_lambda)\n",
    "else:\n",
    "    print(f\"So, OLS wins.\")\n",
    "    winner = LinearRegression()\n",
    "\n",
    "# build winner model\n",
    "winner = Ridge(alpha=best_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_LHw7S6aiyqj",
   "metadata": {
    "id": "_LHw7S6aiyqj"
   },
   "source": [
    "### (3) build winning model on whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kusUZMXGiyqj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1679073432887,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "kusUZMXGiyqj",
    "outputId": "5a6f78af-fcbc-4966-9ecd-6f5b9d23c34e"
   },
   "outputs": [],
   "source": [
    "winner.fit(X_learn, y_learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vsBe0RGniyqj",
   "metadata": {
    "id": "vsBe0RGniyqj"
   },
   "source": [
    "### (4) estimate predictive error of trained final model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8EIuPgXmiyqj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1679073432887,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "8EIuPgXmiyqj",
    "outputId": "2f7748bf-9988-4289-ac29-110b4aedd9d8"
   },
   "outputs": [],
   "source": [
    "test_score = mean_squared_error(y_test, winner.predict(X_test))\n",
    "print(f\"The TEST mse of final model is: {test_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xDutHGa0iyqj",
   "metadata": {
    "id": "xDutHGa0iyqj"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g-loV4Rkiyqk",
   "metadata": {
    "id": "g-loV4Rkiyqk"
   },
   "source": [
    "## Exercises for you: implement any (or both) of the missing strategies \n",
    "\n",
    "- [ ] 10x3 cross-validation (iterated cross-val)\n",
    "- [ ] Monte-Carlo train/val splits (10 repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PaS4QjZOiyqk",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1679073432888,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "PaS4QjZOiyqk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wh-wYKdliyqk",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1679073432888,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "wh-wYKdliyqk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QOmgAuEaiyqk",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1679073432889,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "QOmgAuEaiyqk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rrRZ1eBQiyqk",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1679073432889,
     "user": {
      "displayName": "Marta Arias Vicente",
      "userId": "13874328413650848050"
     },
     "user_tz": -60
    },
    "id": "rrRZ1eBQiyqk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "281px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
