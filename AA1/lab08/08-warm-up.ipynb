{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e01f4d90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# AA1 lab 08  \n",
    "# Warm-up: boosting, bagging with trees with 'diabetes' dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d89559e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46095cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc204a2b",
   "metadata": {},
   "source": [
    "## Random Forests and Boosting\n",
    "\n",
    "We are going to make a simple comparison between bagging and boosting using trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bbc796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ti figure out how many cores and run in parallel random forests\n",
    "\n",
    "N_CORES = joblib.cpu_count(only_physical_cores=True)\n",
    "print(f\"Number of physical cores: {N_CORES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec4c03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc02a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# we'll place results here..\n",
    "\n",
    "results = {k + \"-crossval\": [] for k in [\"rf\", \"gb\"]}\n",
    "\n",
    "T_vals = np.geomspace(1, 300, num=50, dtype=int)\n",
    "\n",
    "rf_time = 0\n",
    "gb_time = 0\n",
    "\n",
    "for T in tqdm(T_vals, total=len(T_vals)):\n",
    "    rfc = RandomForestRegressor(\n",
    "        n_estimators=T, n_jobs=N_CORES, criterion=\"squared_error\"\n",
    "    )\n",
    "    res = cross_validate(rfc, X, y, cv=5)\n",
    "    results[\"rf-crossval\"].append(np.mean(res[\"test_score\"]))\n",
    "    rf_time += np.mean(res[\"fit_time\"])\n",
    "\n",
    "    gbc = GradientBoostingRegressor(n_estimators=T, loss=\"squared_error\")\n",
    "    res = cross_validate(gbc, X, y, cv=5)\n",
    "    results[\"gb-crossval\"].append(np.mean(res[\"test_score\"]))\n",
    "    gb_time += np.mean(res[\"fit_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345dbf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for k in results:\n",
    "    plt.plot(np.array(T_vals), np.array(results[k]), label=k)\n",
    "plt.legend()\n",
    "\n",
    "print(f\"time for random forests: {rf_time:.2f}s\")\n",
    "print(f\"time for gradient boosting: {gb_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f851a7f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
