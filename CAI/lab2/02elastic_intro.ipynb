{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAI Lab Session 2: Intro to ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session you will learn:\n",
    "\n",
    "- a few basics of the `ElasticSearch` database\n",
    "- how to index a set of documents and how to ask simple queries about these documents\n",
    "- how to do this from `Python`\n",
    "- based on the previous, you will compute the boolean and tf-idf matrix for the toy corpus used in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ElasticSearch\n",
    "\n",
    "[ElasticSearch](https://www.elastic.co/) is a _NoSQL/document_ database with the capability of indexing and searching text documents. As a rough analogue, we can use the following table for the equivalence between ElasticSearch and a more classical relational database:\n",
    "\n",
    "| Relational DB | ElasticSearch |\n",
    "|---|---|\n",
    "| Database | Index |\n",
    "| Table | Type |\n",
    "| Row / record | Document |\n",
    "| Column | Field |\n",
    "\n",
    "An index can be thought of as an optimized collection of documents and each document is a collection of fields, which are the key-value pairs that contain your data.\n",
    "\n",
    "`ElasticSearch` is a pretty big beast with many options. Luckily, there is much documentation, a few useful links are:\n",
    "\n",
    "- Here is the [full documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)\n",
    "- Intros you may want to have a look at: \n",
    "    - https://medium.com/expedia-group-tech/getting-started-with-elastic-search-6af62d7df8dd\n",
    "    - http://joelabrahamsson.com/elasticsearch-101\n",
    "- You found another one that you liked? Let us know. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running ElasticSearch\n",
    "\n",
    "First you will need to install `ElasticSearch` following instructions in their [documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html).\n",
    "\n",
    "This database runs as a web service in a machine and can be accessed using a REST web API; however we will interact with the database through its python libraries `elasticsearch-py` and `elasticsearch-dsl`, so you will need to install these as well.  You can run `ElasticSearch` by typing from the command-line prompt:\n",
    "\n",
    "```\n",
    "$ <path_to_elasticsearch_bin>/elasticsearch &\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few seconds (and a lot of logging) the database will be up and running; you may need to hit return for the prompt to show up. To test whether `ElasticSearch` is working execute the code in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'{\\n  \"name\" : \"4b2ded1db0ee\",\\n  \"cluster_name\" : \"elasticsearch\",\\n  \"clus'\n",
      " b'ter_uuid\" : \"Ma9z_GjaSt6LzewCd02koA\",\\n  \"version\" : {\\n    \"number\" : \"7.'\n",
      " b'17.13\",\\n    \"build_flavor\" : \"default\",\\n    \"build_type\" : \"deb\",\\n    \"b'\n",
      " b'uild_hash\" : \"2b211dbb8bfdecaf7f5b44d356bdfe54b1050c13\",\\n    \"build_date'\n",
      " b'\" : \"2023-08-31T17:33:19.958690787Z\",\\n    \"build_snapshot\" : false,\\n    '\n",
      " b'\"lucene_version\" : \"8.11.1\",\\n    \"minimum_wire_compatibility_version\" : '\n",
      " b'\"6.8.0\",\\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\\n  },\\n'\n",
      " b'  \"tagline\" : \"You Know, for Search\"\\n}\\n')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "try:\n",
    "    resp = requests.get('http://localhost:9200/')\n",
    "    pprint(resp.content)\n",
    "    \n",
    "except Exception:\n",
    "    print('elasticsearch is not running')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `ElasticSearch` is working you will see an answer from the server; otherwise you will see a message indicating that it is not running. You can try also throwing the URL http://localhost:9200 to your browser; you should get a similar answer.\n",
    "\n",
    "**In version 8 they introduced enhanced security, which may give you trouble when executing the code here, to deal with this you can either install an earlier version (7 or older) or turn off security settings in their `config/elasticsearch.yml` config file (just set to _false_ everything concerning the security options).** Since we are using the database in offline, local mode this should not be a problem.\n",
    "\n",
    "Also, you should run this script locally in your machine, if you use Google Collab or similar this is not going to work because elasticsearch should be running on the machine where the script is being executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Indexing and querying\n",
    "\n",
    "`ElasticSearch` is a database that allows storing documents (tables do not need a predefined schema as in relational databases). Text in these documents can be processed so the queries extend beyond exact matches allowing complex queries, fuzzy matching and ranking documents respect to the actual match. \n",
    "\n",
    "These kinds of databases are behind search engines like Google Search or Bing.\n",
    "\n",
    "There are different ways of operating with ElasticSearch. It is deployed esentially as a web service with a REST API, so it can be accessed basically from any language with a library for operating with HTTP servers.\n",
    "\n",
    "We are going to use two python libraries for programming on top of ElasticSearch: `elasticsearch` and `elasticsearch-dsl`. Both provide access to ElasticSearch functionalities hiding and making more programming-friendly the interactions, the second one is more convenient for configurating and searching. Make sure both python libraries are installed to proceed with this session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to see the essential elements for developing the session but feel free to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interact with ElasticSearch with need a client object of type `Elasticsearch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "client = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this client you have a connection for operating with Elastic search. Now we will create an index. There are index operations in each library, but the one in `elasticseach-dsl` is simpler to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import Index\n",
    "\n",
    "index = Index('test', using=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will need some text to index, for testing purposes we are going to use the python library `loremipsum`. We will need to install it first if it is not installed already, uncomment the code in next cell if you need to install the library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create some random paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Modi voluptatem dolore sed neque aliquam tempora amet. Etincidunt dolorem etincidunt ut porro quaerat quaerat. Neque dolore eius velit dolore voluptatem quaerat. Adipisci numquam amet adipisci. Sed quiquia dolorem amet sed. Ipsum non aliquam adipisci numquam.\n"
     ]
    }
   ],
   "source": [
    "import lorem\n",
    "\n",
    "texts = [lorem.paragraph() for _ in range(10)]\n",
    "print(len(texts))\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can index the paragraphs in ElasticSearch using the `index` method. The document is passed as a python dictionary with the `body` parameter. The keys of the dictionary will be the fields of the document, in this case we well have only one (`text`) -- here, we use this tag but could use anything we wanted to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing new text: Modi voluptatem dolore sed neque aliquam tempora amet. Etincidunt dolo ...\n",
      "Indexing new text: Velit labore modi eius tempora tempora labore neque. Etincidunt tempor ...\n",
      "Indexing new text: Quiquia eius ut quaerat dolore. Magnam modi velit amet. Adipisci conse ...\n",
      "Indexing new text: Eius eius quisquam sit dolore est. Amet sit tempora dolor. Amet numqua ...\n",
      "Indexing new text: Adipisci etincidunt est sed est numquam non. Dolor modi magnam tempora ...\n",
      "Indexing new text: Dolor non dolor numquam sit amet modi tempora. Non dolor quaerat sit d ...\n",
      "Indexing new text: Porro tempora est adipisci magnam. Voluptatem sit modi porro. Aliquam  ...\n",
      "Indexing new text: Est tempora ipsum labore aliquam. Eius dolor aliquam magnam magnam ut  ...\n",
      "Indexing new text: Aliquam ut velit porro quisquam labore. Tempora non sit neque ipsum. D ...\n",
      "Indexing new text: Consectetur eius labore magnam porro. Dolorem ipsum est neque est modi ...\n"
     ]
    }
   ],
   "source": [
    "for t in texts:\n",
    "    client.index(index=\"test\", document={'text': t})\n",
    "    print(f'Indexing new text: {t[:70]} ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we want to get all docs in the index, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got {'value': 40, 'relation': 'eq'} hits:\n",
      "{'text': 'Ipsum neque modi quiquia magnam eius. Modi ipsum ut amet numquam '\n",
      "         'dolore etincidunt. Velit adipisci sit dolorem magnam dolor dolor. '\n",
      "         'Dolor dolorem neque quaerat. Dolor quisquam dolor dolorem ut non. '\n",
      "         'Tempora porro ut eius voluptatem neque numquam.'}\n",
      "{'text': 'Non dolor sed quiquia numquam labore. Voluptatem quiquia ut numquam. '\n",
      "         'Sed amet neque modi ipsum. Dolor est velit numquam. Consectetur '\n",
      "         'adipisci etincidunt consectetur. Amet labore est etincidunt quaerat '\n",
      "         'aliquam porro. Quiquia tempora dolore quiquia. Labore voluptatem '\n",
      "         'magnam magnam modi neque sit. Consectetur quaerat neque quiquia '\n",
      "         'quiquia.'}\n",
      "{'text': 'Neque eius labore amet aliquam. Adipisci modi voluptatem etincidunt '\n",
      "         'tempora numquam ut. Porro magnam voluptatem sit. Sit etincidunt '\n",
      "         'velit est porro. Quiquia non amet consectetur est est. Dolorem dolor '\n",
      "         'velit voluptatem ipsum quisquam.'}\n",
      "{'text': 'Etincidunt ut magnam dolore porro velit quisquam. Amet dolor ipsum '\n",
      "         'dolorem modi. Consectetur quiquia amet labore dolorem porro. Neque '\n",
      "         'porro quisquam est. Neque quisquam neque amet sed consectetur '\n",
      "         'dolorem ipsum. Sit eius modi porro porro. Sit sit sed velit quaerat '\n",
      "         'eius dolorem. Aliquam dolore adipisci numquam.'}\n",
      "{'text': 'Amet sed ut aliquam. Eius etincidunt ut amet dolor. Adipisci quiquia '\n",
      "         'quiquia quaerat. Quaerat aliquam consectetur quiquia. Ut adipisci '\n",
      "         'ipsum dolor labore numquam. Adipisci tempora dolorem voluptatem '\n",
      "         'dolorem ut. Tempora velit voluptatem porro neque amet. Quaerat non '\n",
      "         'consectetur sed.'}\n",
      "{'text': 'Tempora quisquam adipisci labore dolore neque aliquam etincidunt. Ut '\n",
      "         'non ipsum dolore eius velit aliquam. Amet tempora eius quisquam '\n",
      "         'dolor labore sed. Ut porro quaerat velit dolor magnam sed '\n",
      "         'etincidunt. Numquam numquam amet dolor adipisci sit modi dolor. '\n",
      "         'Numquam consectetur ipsum quaerat quaerat. Labore quiquia dolor sed '\n",
      "         'modi. Sed dolorem dolorem etincidunt. Porro labore eius ut neque sed '\n",
      "         'adipisci dolorem.'}\n",
      "{'text': 'Eius porro modi aliquam etincidunt consectetur velit est. Voluptatem '\n",
      "         'neque magnam porro ipsum porro aliquam. Adipisci quisquam sed amet '\n",
      "         'ipsum numquam. Numquam modi quaerat etincidunt magnam neque non '\n",
      "         'aliquam. Labore modi ipsum labore etincidunt amet sit. Labore modi '\n",
      "         'amet aliquam sed sit. Numquam non quiquia voluptatem etincidunt. '\n",
      "         'Amet aliquam quaerat sed voluptatem modi voluptatem modi. Velit sit '\n",
      "         'consectetur non ipsum eius modi.'}\n",
      "{'text': 'Dolor consectetur velit eius etincidunt tempora. Sit quisquam porro '\n",
      "         'aliquam modi etincidunt voluptatem. Ipsum amet non velit ipsum. '\n",
      "         'Tempora sed velit labore velit aliquam etincidunt. Quaerat porro '\n",
      "         'voluptatem ut consectetur velit.'}\n",
      "{'text': 'Ut dolorem non tempora ipsum aliquam non. Porro quiquia consectetur '\n",
      "         'modi labore quaerat. Porro magnam dolore sed dolorem est. Dolor ut '\n",
      "         'velit amet ipsum dolore consectetur dolor. Labore dolorem ut magnam '\n",
      "         'numquam quaerat. Velit non amet non consectetur eius. Modi non '\n",
      "         'tempora quaerat. Numquam dolore ipsum aliquam ipsum tempora quiquia '\n",
      "         'ut.'}\n",
      "{'text': 'Numquam etincidunt neque voluptatem eius sed voluptatem tempora. Ut '\n",
      "         'tempora porro dolore. Neque ut eius neque consectetur dolore '\n",
      "         'quaerat. Ipsum quiquia etincidunt dolorem numquam velit amet '\n",
      "         'consectetur. Dolore numquam dolorem labore etincidunt magnam.'}\n"
     ]
    }
   ],
   "source": [
    "# get all docs in index 'test'\n",
    "resp = client.search(index=\"test\")\n",
    "\n",
    "# print them\n",
    "print(f\"Got {resp['hits']['total']} hits:\")\n",
    "for hit in resp['hits']['hits']:\n",
    "    pprint(hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search for documents that contain a given keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 matches.\n",
      "\n",
      "ID: DUDwx4oBLFg3lKHMLhib\n",
      "Text: Ipsum neque modi quiquia magnam eius. Modi ipsum ut amet numquam dolore etincidunt. Velit adipisci sit dolorem magnam dolor dolor. Dolor dolorem neque quaerat. Dolor quisquam dolor dolorem ut non. Tempora porro ut eius voluptatem neque numquam.\n",
      "\n",
      "ID: F0Dwx4oBLFg3lKHMvBi5\n",
      "Text: Ipsum neque modi quiquia magnam eius. Modi ipsum ut amet numquam dolore etincidunt. Velit adipisci sit dolorem magnam dolor dolor. Dolor dolorem neque quaerat. Dolor quisquam dolor dolorem ut non. Tempora porro ut eius voluptatem neque numquam.\n",
      "\n",
      "ID: JkDwx4oBLFg3lKHM9Rjb\n",
      "Text: Dolor non dolor numquam sit amet modi tempora. Non dolor quaerat sit dolorem velit non dolore. Sit dolorem ipsum etincidunt etincidunt velit. Quaerat porro labore modi etincidunt ipsum dolorem eius. Quiquia amet aliquam magnam. Neque dolor quaerat ut consectetur etincidunt ipsum dolorem.\n",
      "\n",
      "ID: MEDxx4oBLFg3lKHMBhiS\n",
      "Text: Dolor non dolor numquam sit amet modi tempora. Non dolor quaerat sit dolorem velit non dolore. Sit dolorem ipsum etincidunt etincidunt velit. Quaerat porro labore modi etincidunt ipsum dolorem eius. Quiquia amet aliquam magnam. Neque dolor quaerat ut consectetur etincidunt ipsum dolorem.\n",
      "\n",
      "ID: EkDwx4oBLFg3lKHMLhi6\n",
      "Text: Tempora quisquam adipisci labore dolore neque aliquam etincidunt. Ut non ipsum dolore eius velit aliquam. Amet tempora eius quisquam dolor labore sed. Ut porro quaerat velit dolor magnam sed etincidunt. Numquam numquam amet dolor adipisci sit modi dolor. Numquam consectetur ipsum quaerat quaerat. Labore quiquia dolor sed modi. Sed dolorem dolorem etincidunt. Porro labore eius ut neque sed adipisci dolorem.\n",
      "\n",
      "ID: HEDwx4oBLFg3lKHMvBjh\n",
      "Text: Tempora quisquam adipisci labore dolore neque aliquam etincidunt. Ut non ipsum dolore eius velit aliquam. Amet tempora eius quisquam dolor labore sed. Ut porro quaerat velit dolor magnam sed etincidunt. Numquam numquam amet dolor adipisci sit modi dolor. Numquam consectetur ipsum quaerat quaerat. Labore quiquia dolor sed modi. Sed dolorem dolorem etincidunt. Porro labore eius ut neque sed adipisci dolorem.\n",
      "\n",
      "ID: EUDwx4oBLFg3lKHMLhi4\n",
      "Text: Amet sed ut aliquam. Eius etincidunt ut amet dolor. Adipisci quiquia quiquia quaerat. Quaerat aliquam consectetur quiquia. Ut adipisci ipsum dolor labore numquam. Adipisci tempora dolorem voluptatem dolorem ut. Tempora velit voluptatem porro neque amet. Quaerat non consectetur sed.\n",
      "\n",
      "ID: G0Dwx4oBLFg3lKHMvBjb\n",
      "Text: Amet sed ut aliquam. Eius etincidunt ut amet dolor. Adipisci quiquia quiquia quaerat. Quaerat aliquam consectetur quiquia. Ut adipisci ipsum dolor labore numquam. Adipisci tempora dolorem voluptatem dolorem ut. Tempora velit voluptatem porro neque amet. Quaerat non consectetur sed.\n",
      "\n",
      "ID: DkDwx4oBLFg3lKHMLhix\n",
      "Text: Non dolor sed quiquia numquam labore. Voluptatem quiquia ut numquam. Sed amet neque modi ipsum. Dolor est velit numquam. Consectetur adipisci etincidunt consectetur. Amet labore est etincidunt quaerat aliquam porro. Quiquia tempora dolore quiquia. Labore voluptatem magnam magnam modi neque sit. Consectetur quaerat neque quiquia quiquia.\n",
      "\n",
      "ID: GEDwx4oBLFg3lKHMvBjI\n",
      "Text: Non dolor sed quiquia numquam labore. Voluptatem quiquia ut numquam. Sed amet neque modi ipsum. Dolor est velit numquam. Consectetur adipisci etincidunt consectetur. Amet labore est etincidunt quaerat aliquam porro. Quiquia tempora dolore quiquia. Labore voluptatem magnam magnam modi neque sit. Consectetur quaerat neque quiquia quiquia.\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch_dsl import Search\n",
    "\n",
    "# the following search query specifies the field where we want to search\n",
    "s_obj = Search(using=client, index='test')\n",
    "sq = s_obj.query('match', text='dolor')\n",
    "resp = sq.execute()\n",
    "\n",
    "print(f'Found {len(resp)} matches.')\n",
    "\n",
    "for hit in resp:\n",
    "    print(f'\\nID: {hit.meta.id}\\nText: {hit.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Counting words and docs\n",
    "\n",
    "`Elastic search` helps us to obtain the counts of words in each document. For example, the following code obtains the counts of words of a whole index by adding the counts of words obtained from each document through the functionality of `termvectors`. This function also allows us to get _document counts_ for computing tf-idf weights, by setting the `term_statistics` option to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch.helpers import scan\n",
    "from collections import Counter\n",
    "\n",
    "# Search for all the documents and query the list of (word, frequency) of each one\n",
    "# Totals are accumulated using a Counter\n",
    "word_counts = Counter()\n",
    "sc = scan(client, index='test', query={\"query\" : {\"match_all\": {}}})\n",
    "for s in sc:\n",
    "    doc_counts = Counter()   # I place the counter here so that it is overwritten each time, since doc_freq is constant for every doc\n",
    "    tv = client.termvectors(index='test', id=s['_id'], fields=['text'], term_statistics=True, positions=False)\n",
    "    if 'text' in tv['term_vectors']:   # just in case some document has no field named 'text'\n",
    "        for t in tv['term_vectors']['text']['terms']:\n",
    "            word = t\n",
    "            count = tv['term_vectors']['text']['terms'][t]['term_freq']\n",
    "            df = tv['term_vectors']['text']['terms'][t]['doc_freq']\n",
    "            #pprint(tv['term_vectors']['text']['terms'][t])\n",
    "            word_counts.update({word: count})\n",
    "            doc_counts.update({word: df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('etincidunt', 86),\n",
       " ('amet', 84),\n",
       " ('tempora', 84),\n",
       " ('modi', 82),\n",
       " ('ipsum', 78),\n",
       " ('ut', 74),\n",
       " ('consectetur', 74),\n",
       " ('quaerat', 72),\n",
       " ('numquam', 70),\n",
       " ('porro', 70),\n",
       " ('dolorem', 68),\n",
       " ('aliquam', 68),\n",
       " ('sed', 66),\n",
       " ('sit', 64),\n",
       " ('labore', 64),\n",
       " ('dolor', 62),\n",
       " ('eius', 62),\n",
       " ('neque', 62),\n",
       " ('velit', 60),\n",
       " ('magnam', 56),\n",
       " ('non', 56),\n",
       " ('est', 54),\n",
       " ('adipisci', 52),\n",
       " ('dolore', 52),\n",
       " ('quiquia', 52),\n",
       " ('voluptatem', 48),\n",
       " ('quisquam', 36)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show word frequencies\n",
    "word_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eius', 38),\n",
       " ('etincidunt', 38),\n",
       " ('ipsum', 38),\n",
       " ('porro', 38),\n",
       " ('ut', 38),\n",
       " ('consectetur', 36),\n",
       " ('modi', 36),\n",
       " ('tempora', 36),\n",
       " ('aliquam', 34),\n",
       " ('magnam', 34),\n",
       " ('numquam', 34),\n",
       " ('dolorem', 32),\n",
       " ('labore', 32),\n",
       " ('neque', 32),\n",
       " ('quiquia', 32),\n",
       " ('dolore', 30),\n",
       " ('voluptatem', 28),\n",
       " ('est', 26)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show doc freq\n",
    "doc_counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleanup\n",
    "\n",
    "Finally, we remove the test index.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Proposed simple exercise\n",
    "\n",
    "To get more familiar with elasticsearch, we propose that you _generate the Boolean and tf-idf matrices_ for the toy example that we used in class. You will find 7 text documents that contain the toy documents with the materials for this session in the racó. The steps to follow are:\n",
    "\n",
    "- create an empty index\n",
    "- open each text document in the `toy-docs` folder provided, read its contents and add it to the index as a new document; your index should contain 7 documents after this\n",
    "- use the `termvectors` function to obtain term and doc counts, generate Boolean and tf-idf matrices based on these counts\n",
    "- double check that your results coincide with the numbers in theory slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    index.delete()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "index = Index(\"toy-docs\", using=client)\n",
    "\n",
    "docs = os.listdir(\"toy-docs\")\n",
    "for i, doc in enumerate(docs):\n",
    "    with open(f\"./toy-docs/{doc}\", 'r') as file:\n",
    "        data = file.read().replace('\\n', '')\n",
    "    client.index(index=\"toy-docs\", document={\"text\": data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got {'value': 7, 'relation': 'eq'} hits:\n",
      "{'text': 'four five'}\n",
      "{'text': 'three three three six six'}\n",
      "{'text': 'one two two two two three six six'}\n",
      "{'text': 'three four four four six'}\n",
      "{'text': 'one three'}\n",
      "{'text': 'two two three'}\n",
      "{'text': 'one three four five five five'}\n"
     ]
    }
   ],
   "source": [
    "# get all docs in index 'test'\n",
    "resp = client.search(index=\"toy-docs\")\n",
    "\n",
    "# print them\n",
    "print(f\"Got {resp['hits']['total']} hits:\")\n",
    "for hit in resp['hits']['hits']:\n",
    "    pprint(hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for all the documents and query the list of (word, frequency) of each one\n",
    "# Totals are accumulated using a Counter\n",
    "word_counts = Counter()\n",
    "sc = scan(client, index=\"toy-docs\", query={\"query\" : {\"match_all\": {}}})\n",
    "for s in sc:\n",
    "    doc_counts = Counter()   # I place the counter here so that it is overwritten each time, since doc_freq is constant for every doc\n",
    "    tv = client.termvectors(index=\"toy-docs\", id=s['_id'], fields=['text'], term_statistics=True, positions=False)\n",
    "    if 'text' in tv['term_vectors']:   # just in case some document has no field named 'text'\n",
    "        for t in tv['term_vectors']['text']['terms']:\n",
    "            word = t\n",
    "            count = tv['term_vectors']['text']['terms'][t]['term_freq']\n",
    "            df = tv['term_vectors']['text']['terms'][t]['doc_freq']\n",
    "            #pprint(tv['term_vectors']['text']['terms'][t])\n",
    "            word_counts.update({word: count})\n",
    "            doc_counts.update({word: df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('three', 16),\n",
       " ('two', 12),\n",
       " ('four', 10),\n",
       " ('six', 10),\n",
       " ('five', 8),\n",
       " ('one', 6)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('three', 12), ('four', 6), ('one', 6), ('five', 4)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "135px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
