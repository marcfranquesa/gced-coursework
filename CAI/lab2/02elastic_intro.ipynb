{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAI Lab Session 2: Intro to ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session you will learn:\n",
    "\n",
    "- a few basics of the `ElasticSearch` database\n",
    "- how to index a set of documents and how to ask simple queries about these documents\n",
    "- how to do this from `Python`\n",
    "- based on the previous, you will compute the boolean and tf-idf matrix for the toy corpus used in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ElasticSearch\n",
    "\n",
    "[ElasticSearch](https://www.elastic.co/) is a _NoSQL/document_ database with the capability of indexing and searching text documents. As a rough analogue, we can use the following table for the equivalence between ElasticSearch and a more classical relational database:\n",
    "\n",
    "| Relational DB | ElasticSearch |\n",
    "|---|---|\n",
    "| Database | Index |\n",
    "| Table | Type |\n",
    "| Row / record | Document |\n",
    "| Column | Field |\n",
    "\n",
    "An index can be thought of as an optimized collection of documents and each document is a collection of fields, which are the key-value pairs that contain your data.\n",
    "\n",
    "`ElasticSearch` is a pretty big beast with many options. Luckily, there is much documentation, a few useful links are:\n",
    "\n",
    "- Here is the [full documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)\n",
    "- Intros you may want to have a look at: \n",
    "    - https://medium.com/expedia-group-tech/getting-started-with-elastic-search-6af62d7df8dd\n",
    "    - http://joelabrahamsson.com/elasticsearch-101\n",
    "- You found another one that you liked? Let us know. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running ElasticSearch\n",
    "\n",
    "First you will need to install `ElasticSearch` following instructions in their [documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html).\n",
    "\n",
    "This database runs as a web service in a machine and can be accessed using a REST web API; however we will interact with the database through its python libraries `elasticsearch-py` and `elasticsearch-dsl`, so you will need to install these as well.  You can run `ElasticSearch` by typing from the command-line prompt:\n",
    "\n",
    "```\n",
    "$ <path_to_elasticsearch_bin>/elasticsearch &\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few seconds (and a lot of logging) the database will be up and running; you may need to hit return for the prompt to show up. To test whether `ElasticSearch` is working execute the code in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticsearch is not running\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "try:\n",
    "    resp = requests.get('http://localhost:9200/')\n",
    "    pprint(resp.content)\n",
    "    \n",
    "except Exception:\n",
    "    print('elasticsearch is not running')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `ElasticSearch` is working you will see an answer from the server; otherwise you will see a message indicating that it is not running. You can try also throwing the URL http://localhost:9200 to your browser; you should get a similar answer.\n",
    "\n",
    "**In version 8 they introduced enhanced security, which may give you trouble when executing the code here, to deal with this you can either install an earlier version (7 or older) or turn off security settings in their `config/elasticsearch.yml` config file (just set to _false_ everything concerning the security options).** Since we are using the database in offline, local mode this should not be a problem.\n",
    "\n",
    "Also, you should run this script locally in your machine, if you use Google Collab or similar this is not going to work because elasticsearch should be running on the machine where the script is being executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Indexing and querying\n",
    "\n",
    "`ElasticSearch` is a database that allows storing documents (tables do not need a predefined schema as in relational databases). Text in these documents can be processed so the queries extend beyond exact matches allowing complex queries, fuzzy matching and ranking documents respect to the actual match. \n",
    "\n",
    "These kinds of databases are behind search engines like Google Search or Bing.\n",
    "\n",
    "There are different ways of operating with ElasticSearch. It is deployed esentially as a web service with a REST API, so it can be accessed basically from any language with a library for operating with HTTP servers.\n",
    "\n",
    "We are going to use two python libraries for programming on top of ElasticSearch: `elasticsearch` and `elasticsearch-dsl`. Both provide access to ElasticSearch functionalities hiding and making more programming-friendly the interactions, the second one is more convenient for configurating and searching. Make sure both python libraries are installed to proceed with this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch in /Users/marias/Library/Python/3.7/lib/python/site-packages (8.9.0)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in /Users/marias/Library/Python/3.7/lib/python/site-packages (from elasticsearch) (8.4.0)\n",
      "Requirement already satisfied: urllib3<2,>=1.26.2 in /Users/marias/Library/Python/3.7/lib/python/site-packages (from elastic-transport<9,>=8->elasticsearch) (1.26.16)\n",
      "Requirement already satisfied: certifi in /Users/marias/Library/Python/3.7/lib/python/site-packages (from elastic-transport<9,>=8->elasticsearch) (2023.7.22)\n",
      "Requirement already satisfied: elasticsearch-dsl in /Users/marias/Library/Python/3.7/lib/python/site-packages (8.9.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/site-packages (from elasticsearch-dsl) (2.7.5)\n",
      "Requirement already satisfied: elasticsearch<9.0.0,>=8.0.0 in /Users/marias/Library/Python/3.7/lib/python/site-packages (from elasticsearch-dsl) (8.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil->elasticsearch-dsl) (1.11.0)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in /Users/marias/Library/Python/3.7/lib/python/site-packages (from elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (8.4.0)\n",
      "Requirement already satisfied: urllib3<2,>=1.26.2 in /Users/marias/Library/Python/3.7/lib/python/site-packages (from elastic-transport<9,>=8->elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (1.26.16)\n",
      "Requirement already satisfied: certifi in /Users/marias/Library/Python/3.7/lib/python/site-packages (from elastic-transport<9,>=8->elasticsearch<9.0.0,>=8.0.0->elasticsearch-dsl) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install elasticsearch --user\n",
    "!pip3 install elasticsearch-dsl --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to see the essential elements for developing the session but feel free to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interact with ElasticSearch with need a client object of type `Elasticsearch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "client = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this client you have a connection for operating with Elastic search. Now we will create an index. There are index operations in each library, but the one in `elasticseach-dsl` is simpler to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import Index\n",
    "\n",
    "index = Index('test', using=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will need some text to index, for testing purposes we are going to use the python library `loremipsum`. We will need to install it first if it is not installed already, uncomment the code in next cell if you need to install the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lorem in /Users/marias/Library/Python/3.7/lib/python/site-packages (0.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install lorem --user  # Restart the kernel if you are not able to import the library in the next cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create some random paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Quisquam ipsum ut sed. Est numquam adipisci quaerat modi. Quiquia quaerat est dolore modi amet. Non voluptatem eius non. Ipsum est non labore. Quisquam quiquia sit magnam amet neque porro. Etincidunt sit etincidunt sit sed ut. Aliquam tempora sit quaerat tempora quisquam magnam velit. Quiquia voluptatem est dolorem. Velit ipsum etincidunt amet numquam dolore.\n"
     ]
    }
   ],
   "source": [
    "import lorem\n",
    "\n",
    "texts = [lorem.paragraph() for _ in range(10)]\n",
    "print(len(texts))\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can index the paragraphs in ElasticSearch using the `index` method. The document is passed as a python dictionary with the `body` parameter. The keys of the dictionary will be the fields of the document, in this case we well have only one (`text`) -- here, we use this tag but could use anything we wanted to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing new text: Quisquam ipsum ut sed. Est numquam adipisci quaerat modi. Quiquia quae ...\n",
      "Indexing new text: Dolore tempora eius aliquam consectetur quaerat ipsum. Eius numquam ei ...\n",
      "Indexing new text: Ut quaerat quiquia quaerat numquam. Velit dolorem dolore velit tempora ...\n",
      "Indexing new text: Magnam consectetur quisquam magnam aliquam. Quiquia numquam labore est ...\n",
      "Indexing new text: Aliquam magnam ipsum amet consectetur. Dolore velit aliquam amet dolor ...\n",
      "Indexing new text: Aliquam dolorem etincidunt porro eius. Consectetur dolor ipsum ut ut q ...\n",
      "Indexing new text: Aliquam quisquam consectetur non amet voluptatem voluptatem neque. Ame ...\n",
      "Indexing new text: Est dolor neque voluptatem velit quiquia. Dolorem ut adipisci quisquam ...\n",
      "Indexing new text: Eius dolor non quisquam dolor labore. Quisquam dolore dolore aliquam a ...\n",
      "Indexing new text: Magnam amet adipisci est dolore aliquam. Neque tempora labore amet por ...\n"
     ]
    }
   ],
   "source": [
    "for t in texts:\n",
    "    client.index(index='test', document={'text': t})\n",
    "    print(f'Indexing new text: {t[:70]} ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we want to get all docs in the index, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 8 hits:\n",
      "{'text': 'Quisquam ipsum ut sed. Est numquam adipisci quaerat modi. Quiquia '\n",
      "         'quaerat est dolore modi amet. Non voluptatem eius non. Ipsum est non '\n",
      "         'labore. Quisquam quiquia sit magnam amet neque porro. Etincidunt sit '\n",
      "         'etincidunt sit sed ut. Aliquam tempora sit quaerat tempora quisquam '\n",
      "         'magnam velit. Quiquia voluptatem est dolorem. Velit ipsum etincidunt '\n",
      "         'amet numquam dolore.'}\n",
      "{'text': 'Dolore tempora eius aliquam consectetur quaerat ipsum. Eius numquam '\n",
      "         'eius labore ipsum non quisquam. Consectetur sit amet adipisci neque '\n",
      "         'sed. Aliquam etincidunt velit amet magnam non. Velit aliquam porro '\n",
      "         'quaerat ipsum numquam. Consectetur quaerat aliquam consectetur '\n",
      "         'quiquia dolorem porro.'}\n",
      "{'text': 'Ut quaerat quiquia quaerat numquam. Velit dolorem dolore velit '\n",
      "         'tempora voluptatem eius. Est etincidunt labore magnam. Dolore '\n",
      "         'adipisci aliquam numquam quiquia tempora. Ut dolor modi dolore velit '\n",
      "         'est adipisci voluptatem. Magnam magnam non tempora.'}\n",
      "{'text': 'Magnam consectetur quisquam magnam aliquam. Quiquia numquam labore '\n",
      "         'est est dolore dolorem. Amet dolorem etincidunt adipisci modi '\n",
      "         'voluptatem quiquia. Ipsum voluptatem consectetur tempora velit. '\n",
      "         'Labore quiquia dolore quisquam dolorem neque non. Consectetur neque '\n",
      "         'consectetur velit. Neque dolor tempora labore quiquia sit. Aliquam '\n",
      "         'dolorem neque ipsum etincidunt. Dolor amet velit magnam quisquam. '\n",
      "         'Dolorem non numquam neque ut sed consectetur.'}\n",
      "{'text': 'Aliquam magnam ipsum amet consectetur. Dolore velit aliquam amet '\n",
      "         'dolor dolorem labore. Consectetur consectetur sit aliquam numquam '\n",
      "         'aliquam velit. Dolore sed ut eius voluptatem numquam adipisci. Porro '\n",
      "         'dolor quaerat dolor dolor. Voluptatem voluptatem aliquam dolore. '\n",
      "         'Velit quaerat voluptatem quisquam magnam. Quaerat ipsum eius est.'}\n",
      "{'text': 'Aliquam dolorem etincidunt porro eius. Consectetur dolor ipsum ut ut '\n",
      "         'quiquia magnam. Dolorem eius quaerat eius quisquam sit quiquia. '\n",
      "         'Consectetur labore amet porro voluptatem neque labore. Etincidunt '\n",
      "         'dolorem sed consectetur adipisci neque. Numquam quaerat magnam '\n",
      "         'quisquam tempora. Numquam est quaerat amet. Velit non porro non '\n",
      "         'porro.'}\n",
      "{'text': 'Aliquam quisquam consectetur non amet voluptatem voluptatem neque. '\n",
      "         'Amet ut tempora quaerat consectetur non est numquam. Dolore dolore '\n",
      "         'magnam quisquam neque labore. Est amet magnam tempora aliquam est. '\n",
      "         'Amet dolore neque est aliquam amet.'}\n",
      "{'text': 'Est dolor neque voluptatem velit quiquia. Dolorem ut adipisci '\n",
      "         'quisquam ut. Aliquam dolor velit sit dolor magnam. Non adipisci '\n",
      "         'aliquam non. Eius sed quaerat voluptatem. Ipsum sit magnam dolor '\n",
      "         'labore quisquam sed aliquam. Ipsum consectetur quaerat magnam '\n",
      "         'tempora dolore amet. Est consectetur labore porro. Ut consectetur '\n",
      "         'adipisci labore sit.'}\n"
     ]
    }
   ],
   "source": [
    "# get all docs in index 'test'\n",
    "resp = client.search(index=\"test\", query={\"match_all\": {}})\n",
    "\n",
    "# print them\n",
    "print(f\"Got {resp['hits']['total']['value']} hits:\")\n",
    "for hit in resp['hits']['hits']:\n",
    "    pprint(hit[\"_source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search for documents that contain a given keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 matches.\n",
      "\n",
      "ID: h_fkk4oBvuzMbP3JNVXJ\n",
      "Text: Aliquam magnam ipsum amet consectetur. Dolore velit aliquam amet dolor dolorem labore. Consectetur consectetur sit aliquam numquam aliquam velit. Dolore sed ut eius voluptatem numquam adipisci. Porro dolor quaerat dolor dolor. Voluptatem voluptatem aliquam dolore. Velit quaerat voluptatem quisquam magnam. Quaerat ipsum eius est.\n",
      "\n",
      "ID: ivfkk4oBvuzMbP3JN1W-\n",
      "Text: Est dolor neque voluptatem velit quiquia. Dolorem ut adipisci quisquam ut. Aliquam dolor velit sit dolor magnam. Non adipisci aliquam non. Eius sed quaerat voluptatem. Ipsum sit magnam dolor labore quisquam sed aliquam. Ipsum consectetur quaerat magnam tempora dolore amet. Est consectetur labore porro. Ut consectetur adipisci labore sit.\n",
      "\n",
      "ID: hvfkk4oBvuzMbP3JNVUr\n",
      "Text: Magnam consectetur quisquam magnam aliquam. Quiquia numquam labore est est dolore dolorem. Amet dolorem etincidunt adipisci modi voluptatem quiquia. Ipsum voluptatem consectetur tempora velit. Labore quiquia dolore quisquam dolorem neque non. Consectetur neque consectetur velit. Neque dolor tempora labore quiquia sit. Aliquam dolorem neque ipsum etincidunt. Dolor amet velit magnam quisquam. Dolorem non numquam neque ut sed consectetur.\n",
      "\n",
      "ID: hffkk4oBvuzMbP3JNFWX\n",
      "Text: Ut quaerat quiquia quaerat numquam. Velit dolorem dolore velit tempora voluptatem eius. Est etincidunt labore magnam. Dolore adipisci aliquam numquam quiquia tempora. Ut dolor modi dolore velit est adipisci voluptatem. Magnam magnam non tempora.\n",
      "\n",
      "ID: iPfkk4oBvuzMbP3JNlVp\n",
      "Text: Aliquam dolorem etincidunt porro eius. Consectetur dolor ipsum ut ut quiquia magnam. Dolorem eius quaerat eius quisquam sit quiquia. Consectetur labore amet porro voluptatem neque labore. Etincidunt dolorem sed consectetur adipisci neque. Numquam quaerat magnam quisquam tempora. Numquam est quaerat amet. Velit non porro non porro.\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch_dsl import Search\n",
    "\n",
    "# the following search query specifies the field where we want to search\n",
    "s_obj = Search(using=client, index='test')\n",
    "sq = s_obj.query('match', text='dolor')\n",
    "resp = sq.execute()\n",
    "\n",
    "print(f'Found {len(resp)} matches.')\n",
    "\n",
    "for hit in resp:\n",
    "    print(f'\\nID: {hit.meta.id}\\nText: {hit.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Counting words and docs\n",
    "\n",
    "`Elastic search` helps us to obtain the counts of words in each document. For example, the following code obtains the counts of words of a whole index by adding the counts of words obtained from each document through the functionality of `termvectors`. This function also allows us to get _document counts_ for computing tf-idf weights, by setting the `term_statistics` option to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch.helpers import scan\n",
    "from collections import Counter\n",
    "\n",
    "# Search for all the documents and query the list of (word, frequency) of each one\n",
    "# Totals are accumulated using a Counter\n",
    "word_counts = Counter()\n",
    "sc = scan(client, index='test', query={\"query\" : {\"match_all\": {}}})\n",
    "for s in sc:\n",
    "    doc_counts = Counter()   # I place the counter here so that it is overwritten each time, since doc_freq is constant for every doc\n",
    "    tv = client.termvectors(index='test', id=s['_id'], fields=['text'], term_statistics=True, positions=False)\n",
    "    if 'text' in tv['term_vectors']:   # just in case some document has no field named 'text'\n",
    "        for t in tv['term_vectors']['text']['terms']:\n",
    "            word = t\n",
    "            count = tv['term_vectors']['text']['terms'][t]['term_freq']\n",
    "            df = tv['term_vectors']['text']['terms'][t]['doc_freq']\n",
    "            #pprint(tv['term_vectors']['text']['terms'][t])\n",
    "            word_counts.update({word: count})\n",
    "            doc_counts.update({word: df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aliquam', 20),\n",
       " ('consectetur', 20),\n",
       " ('magnam', 18),\n",
       " ('amet', 17),\n",
       " ('quaerat', 17),\n",
       " ('est', 16),\n",
       " ('velit', 16),\n",
       " ('dolore', 15),\n",
       " ('voluptatem', 15),\n",
       " ('non', 14),\n",
       " ('quisquam', 14),\n",
       " ('dolorem', 13),\n",
       " ('ipsum', 13),\n",
       " ('labore', 13),\n",
       " ('neque', 13),\n",
       " ('numquam', 13),\n",
       " ('quiquia', 13),\n",
       " ('tempora', 12),\n",
       " ('ut', 12),\n",
       " ('dolor', 12),\n",
       " ('eius', 11),\n",
       " ('sit', 11),\n",
       " ('adipisci', 10),\n",
       " ('etincidunt', 9),\n",
       " ('porro', 9),\n",
       " ('sed', 8),\n",
       " ('modi', 4)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show word frequencies\n",
    "word_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aliquam', 10),\n",
       " ('labore', 10),\n",
       " ('magnam', 10),\n",
       " ('adipisci', 9),\n",
       " ('amet', 9),\n",
       " ('dolore', 9),\n",
       " ('est', 9),\n",
       " ('non', 9),\n",
       " ('tempora', 9),\n",
       " ('ut', 9),\n",
       " ('velit', 9),\n",
       " ('dolorem', 8),\n",
       " ('eius', 8),\n",
       " ('ipsum', 8),\n",
       " ('neque', 8),\n",
       " ('quaerat', 8),\n",
       " ('quisquam', 8),\n",
       " ('consectetur', 7),\n",
       " ('dolor', 7),\n",
       " ('porro', 7),\n",
       " ('sed', 7),\n",
       " ('sit', 7),\n",
       " ('voluptatem', 7),\n",
       " ('quiquia', 6)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show doc freq\n",
    "doc_counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Proposed simple exercise\n",
    "\n",
    "To get more familiar with elasticsearch, we propose that you _generate the Boolean and tf-idf matrices_ for the toy example that we used in class. You will find 7 text documents that contain the toy documents with the materials for this session in the racó. The steps to follow are:\n",
    "\n",
    "- create an empty index\n",
    "- open each text document in the `toy-docs` folder provided, read its contents and add it to the index as a new document; your index should contain 7 documents after this\n",
    "- use the `termvectors` function to obtain term and doc counts, generate Boolean and tf-idf matrices based on these counts\n",
    "- double check that your results coincide with the numbers in theory slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleanup\n",
    "\n",
    "Finally, we remove the test index.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "135px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
